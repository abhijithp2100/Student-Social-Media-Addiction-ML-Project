{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1c0d147a-786a-42ca-a699-fd96f25820da",
   "metadata": {},
   "source": [
    "# Machine Learning Project\n",
    "\n",
    "## Student Social Media Addiction with Machine Learning\n",
    "\n",
    "Social media usage among students varies widely in terms of daily screen time, platform preference, sleep patterns, and academic impact. This project uses Linear Regression to analyze these factors and predict students’ social media addiction scores, with the aim of understanding how usage behavior and lifestyle variables contribute to addictive tendencies.\n",
    "\n",
    "### Project Objectives\n",
    "\n",
    "- Perform Exploratory Data Analysis (EDA) to identify patterns, trends, and relationships in students’ social media usage behavior.\n",
    "- Clean and preprocess the dataset using encoding and scaling techniques to prepare it for machine learning.\n",
    "- Select the most relevant features influencing social media addiction scores.\n",
    "- Build and train Linear Regression and K-Nearest Neighbors (KNN) Regression models to predict addiction levels.\n",
    "- Evaluate model performance using R² Score and Mean Absolute Error (MAE).\n",
    "\n",
    "\n",
    "## Exploratory Data Analysis \n",
    "\n",
    "Loading the libraries required for the analysis \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "Loading the dataset\n",
    "\n",
    "df=pd.read_csv(r\"C:\\Users\\Lenovo\\Data Analytics\\Dataset\\Students Social Media Addiction.csv\")\n",
    "df\n",
    "\n",
    "## Understanding the data\n",
    "Understanding the data is a crucial first step in the analysis process. It helps identify key features, data types, and underlying patterns, providing a strong foundation for effective visualization and machine learning modeling.\n",
    "\n",
    "df.columns\n",
    "\n",
    "df.info()\n",
    "\n",
    "df.shape\n",
    "\n",
    "df.describe()\n",
    "\n",
    "df.dtypes\n",
    "\n",
    "## Dropping Unwanted Columns\n",
    "\n",
    "Some columns do not contribute meaningful insights to the analysis or predictive modeling process. Therefore, these unnecessary features are removed to reduce noise and improve model performance.\n",
    "- **Student_ID**: Acts only as a unique identifier and does not provide predictive value for the model.\n",
    "- **Conflicts_Over_Social_Media**: Subjective in nature and may introduce noise without directly improving addiction score prediction.\n",
    "- **Country**: Highly categorical with limited relevance to individual addiction behavior in this dataset.\n",
    "\n",
    "\n",
    "df.drop(columns=['Student_ID','Conflicts_Over_Social_Media',\"Country\"],inplace=True)\n",
    "\n",
    "df.columns\n",
    "\n",
    "## 1. Identifying the Null Values\n",
    "Identifying null values is an essential step in data preprocessing, as missing data can affect analysis accuracy and model performance. Detecting these values early helps determine the appropriate handling strategy.\n",
    "\n",
    "df.isnull().sum()\n",
    "\n",
    "This dataset dosen't contain any null values\n",
    "\n",
    "## Handling the Outliers\n",
    "\n",
    "Handling outliers is an important step in data preprocessing, as extreme values can influence statistical analysis and machine learning model performance. Identifying and evaluating outliers helps decide whether they should be treated or retained based on their relevance.\n",
    "\n",
    "- We are plotting a boxplot to observe the outliers.\n",
    "\n",
    "col=[\"Avg_Daily_Usage_Hours\",'Sleep_Hours_Per_Night','Mental_Health_Score','Addicted_Score']\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.boxplot(data=df[col])\n",
    "plt.tight_layout()\n",
    "\n",
    "From the boxplot analysis, it is evident that `Avg_Daily_Usage_Hours contains` only a small number of outliers, indicating that most observations fall within a reasonable range.\n",
    "\n",
    "Identifying those outliers...\n",
    "\n",
    "Q1=np.percentile(df['Avg_Daily_Usage_Hours'],25,method='midpoint')\n",
    "Q3=np.percentile(df['Avg_Daily_Usage_Hours'],75,method='midpoint')\n",
    "IQR=Q3-Q1\n",
    "upper_limit=Q3+IQR*1.5\n",
    "lower_limit=Q1-IQR*1.5\n",
    "\n",
    "outliers=[]\n",
    "for i in df['Avg_Daily_Usage_Hours']:\n",
    "    if ((i>upper_limit) or (i<lower_limit)):\n",
    "        outliers.append(i)\n",
    "\n",
    "print(outliers)\n",
    "\n",
    "The outliers were retained because they represent realistic and valid variations in daily social media usage rather than data errors.\n",
    "\n",
    "## Visualization \n",
    "\n",
    "Visualization is used to explore patterns, trends, and relationships within the dataset. By visualizing the data, we gain a clearer understanding of student behavior and identify insights that guide further analysis and modeling.m\n",
    "\n",
    "- The first step in visualization is identifying the target column. In this project, the target column is the **Addiction_Score**.\n",
    "\n",
    "#### Questions to Answer\n",
    "- Does increased social media usage lead to higher addiction levels?\n",
    "- How does social media addiction affect sleep and mental health?\n",
    "- Are certain social media platforms more addictive than others?\n",
    "- What is the impact of social media addiction on academic performance?\n",
    "\n",
    "sns.set_theme(style='dark',context='notebook',palette='deep')\n",
    "\n",
    "### Histogram – Daily Social Media Usage Distribution\n",
    "\n",
    "df['Avg_Daily_Usage_Hours'].plot(kind='hist',edgecolor='black')\n",
    "plt.title('Most Students Spend 4-6 hrs/day',fontsize=13, fontweight='bold')\n",
    "plt.xlabel(\"Average Hour\",fontsize=10)\n",
    "plt.savefig(\"a.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "- **Most students spend around 4 to 6 hours every day on social media, which shows that daily usage is quite high among students. Most students spend 4–6 hours per day on social media**\n",
    "- **Only a few students spend very little time on social media, while some students spend more than 7 hours a day, showing that a small group are heavy users.**\n",
    "- **Since many students use social media for several hours daily, it has become a regular habit for most students, which may affect their studies, sleep, or mental health.**\n",
    "\n",
    "### Histogram - Distribution of Social Media Addiction Scores\n",
    "\n",
    "sns.displot(x='Addicted_Score', bins=8, data=df)\n",
    "plt.xlabel(\"Addiction Score\", fontsize=10)\n",
    "plt.ylabel(\"Number of Students\", fontsize=10)\n",
    "plt.title(\"Most Students Show Moderate-to-High Levels of Addiction\", fontsize=13, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"c.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "- **A large proportion of students have an addiction score of 7, indicating that moderate-to-high levels of social media addiction are common among students.**\n",
    "\n",
    "### Bar Chart - Most Used Social Media Platforms Among Students\n",
    "\n",
    "We are finding out the top used 5 platforms\n",
    "\n",
    "platform=df['Most_Used_Platform'].value_counts().head(5).index\n",
    "print(platform)\n",
    "\n",
    "sns.countplot(x='Most_Used_Platform', data=df, order=platform)\n",
    "plt.xlabel(\"Social Media Platform\", fontsize=10)\n",
    "plt.ylabel(\"Number of Students\", fontsize=10)\n",
    "plt.title(\"Instagram Is the Most Used Platform\", fontsize=13, fontweight='bold')\n",
    "\n",
    "- **Instagram is the most used social media platform among students, with a significantly higher number of users compared to all other platforms.**\n",
    "- **Platforms like WhatsApp and Twitter are used by fewer students, indicating that students mainly prefer content-driven and entertainment-focused platforms over messaging or text-based platforms.**\n",
    "\n",
    "### Regression Plot – Addiction Score vs Sleep Hours per Night\n",
    "\n",
    "sns.regplot(x='Addicted_Score',y='Sleep_Hours_Per_Night',data=df,line_kws={'color': 'red'},ci=None,scatter_kws={'alpha': 0.3})\n",
    "plt.xlabel(\"Addiction Score\", fontsize=10)\n",
    "plt.ylabel(\"Sleep Hours per Night\", fontsize=10)\n",
    "plt.title(\"Addiction Score vs Sleep Hours\", fontsize=13, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"d.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "-  **There is a clear negative relationship between addiction score and sleep hours, meaning that as social media addiction increases, students tend to sleep less.**\n",
    "\n",
    "- **Students with lower addiction scores (2–4) generally get 7 to 9 hours of sleep, while students with higher addiction scores (7–9) often sleep between 4 to 6 hours, showing a noticeable drop in sleep duration.**\n",
    "\n",
    "sns.boxplot(x='Affects_Academic_Performance', y='Addicted_Score', data=df)\n",
    "plt.xlabel(\"Affects Academic Performance\", fontsize=10)\n",
    "plt.ylabel(\"Addiction Score\", fontsize=10)\n",
    "plt.title(\"Addiction Score by Academic Impact\", fontsize=13, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"e.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "- **The median addiction score for students whose academics are affected is around 7–8, while it is around 4–5 for students whose academics are not affected, showing a clear difference between the two groups.**.\n",
    "\n",
    "### Bar Plot – Addiction Score by Academic Level and Gender\n",
    "\n",
    "df['Gender'].value_counts()\n",
    "\n",
    "sns.barplot(x='Academic_Level', y='Addicted_Score', data=df, hue='Gender')\n",
    "plt.xlabel(\"Academic Level\", fontsize=10)\n",
    "plt.ylabel(\"Addiction Score\", fontsize=10)\n",
    "plt.title(\"BarPlot–AddictionScoreByAcademicLevelAndGender\", fontsize=13, fontweight='bold')\n",
    "plt.savefig(\"f.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "- **Across all academic levels, high school students show the highest addiction scores, indicating that younger students tend to have higher social media addiction compared to graduate and undergraduate students.**\n",
    "- **Within each academic level, male students generally have slightly higher addiction scores than female students, though the difference is relatively small for undergraduate and graduate levels.**\n",
    "- **But in High School Socail Media Addiction Are Higher Among Females**\n",
    "\n",
    "### Bar Plot – Addiction Score by Relationship Status\n",
    "\n",
    "sns.barplot(x='Relationship_Status', y='Addicted_Score', data=df)\n",
    "plt.xlabel(\"Relationship Status\", fontsize=10)\n",
    "plt.ylabel(\"Addiction Score\", fontsize=10)\n",
    "plt.title(\"Addiction Score by Relationship Status\", fontsize=13, fontweight='bold')\n",
    "plt.savefig(\"g.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "- **Students with a complicated relationship status have the highest average addiction score compared to students who are single or in a relationship.**\n",
    "- **The higher addiction score among students with complicated relationships suggests that emotional stress or relationship issues may lead to increased social media usage**\n",
    "\n",
    "### Heatmap – Correlation Between Numerical Features\n",
    "\n",
    "\n",
    "corr = df.corr(numeric_only=True)\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", linewidth=0.5, center=0, cmap='coolwarm')\n",
    "plt.title(\"Correlation Between Numerical Features\", fontsize=13, fontweight='bold')\n",
    "plt.savefig(\"h.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "- **Addiction score has a strong positive correlation with average daily usage hours (0.83), meaning students who spend more time on social media tend to have much higher addiction levels.**\n",
    "- **Addiction score is strongly negatively correlated with sleep hours (-0.76) and mental health score (-0.95), indicating that higher social media addiction is associated with less sleep and poorer mental health.**\n",
    "\n",
    "### Splitting into Train-Test Split\n",
    "\n",
    "Before building the machine learning model, the dataset is split into training and testing sets. This allows the model to learn patterns from one portion of the data and be evaluated on unseen data to measure its real-world performance.\n",
    "\n",
    "Why Train-Test Split is Performed Before Encoding:\n",
    "- Performing the split before encoding helps prevent data leakage, ensuring that information from the test set does not influence the training process.\n",
    "\n",
    "First, we need to split the dataset into two seperate dataframe\n",
    "- Depentant dataframe\n",
    "- Indepentant dataframe\n",
    "\n",
    "x=df.drop(columns=['Addicted_Score'])\n",
    "x=pd.DataFrame(x)\n",
    "x.head()\n",
    "\n",
    "y=df['Addicted_Score']\n",
    "y=pd.DataFrame(y)\n",
    "y.head()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25,random_state=42)\n",
    "\n",
    "x_train.head()\n",
    "\n",
    "x_test.head()\n",
    "\n",
    "### Encoding\n",
    "\n",
    "- Encoding is the process of converting categorical variables into numerical representations so that they can be interpreted by machine learning algorithms. It is a crucial data preprocessing step that prepares raw data for effective model training.\n",
    "- Here, we are using **Label Encoding** and **One-Hot Encoding** to perform this transformation.\n",
    "\n",
    "df.select_dtypes('object').columns\n",
    "\n",
    "Importing Label Encoder...\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_gender=LabelEncoder()\n",
    "le_academic=LabelEncoder()\n",
    "\n",
    "x_train[\"Gender\"] = le_gender.fit_transform(x_train[\"Gender\"])\n",
    "x_test[\"Gender\"] = le_gender.transform(x_test[\"Gender\"])\n",
    "\n",
    "x_train[\"Affects_Academic_Performance\"] = le_academic.fit_transform(x_train[\"Affects_Academic_Performance\"])\n",
    "x_test[\"Affects_Academic_Performance\"] = le_academic.transform(x_test[\"Affects_Academic_Performance\"])                                                               \n",
    "\n",
    "cols=['Academic_Level','Most_Used_Platform','Relationship_Status']\n",
    "xtrainencoded=pd.get_dummies(x_train,columns=cols,drop_first=True)\n",
    "xtestencoded=pd.get_dummies(x_test,columns=cols,drop_first=True)\n",
    "\n",
    "x_train= xtrainencoded.astype(int)\n",
    "x_test = xtestencoded.astype(int)\n",
    "\n",
    "x_train.head()\n",
    "\n",
    "x_test.head()\n",
    "\n",
    "### Scaling\n",
    "\n",
    "Scaling is the process of transforming numerical features to a common scale so that no single feature dominates the model due to its magnitude. It helps machine learning algorithms perform better and converge faster.\n",
    "\n",
    "Here, we are using **Min-Max Scaling**.\n",
    "\n",
    "**Why Min-Max Scaling?**\n",
    "- It scales features to a **fixed range (usually 0 to 1)**, making the data easier for distance-based and gradient-based models to interpret.\n",
    "- It preserves the **original distribution and relative relationships** between values, which is useful when the data does not contain extreme outliers.\n",
    "\n",
    "df.select_dtypes('number').columns\n",
    "\n",
    "Importing Min Max Scaler...\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "minmax=MinMaxScaler()\n",
    "\n",
    "col=['Age', 'Avg_Daily_Usage_Hours', 'Sleep_Hours_Per_Night','Mental_Health_Score']\n",
    "\n",
    "x_train[col]=minmax.fit_transform(x_train[col])\n",
    "x_test[col]=minmax.transform(x_test[col])\n",
    "\n",
    "x_train.head()\n",
    "\n",
    "x_test.head()\n",
    "\n",
    "## Machine Learning\n",
    "\n",
    "Machine learning is used to predict outcomes by training models to learn patterns and relationships from data. Based on these learned patterns, the models can make predictions on unseen data.\n",
    "\n",
    "In this project, **Linear Regression** is used because the target variable (**Addicted_Score**) is continuous. Additionally, Linear Regression provides a simple and interpretable baseline model to understand how different features influence the predicted addiction score.\n",
    "\n",
    "We also use **KNN Regression** to validate the results and ensure the robustness of the predictions. By comparing the performance of both models, we gain confidence in the model’s ability to generalize and capture both linear and non-linear relationships in the data.\n",
    "\n",
    "### Linear Regression\n",
    "\n",
    "Importing `Linear Regression` Model\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr=LinearRegression()\n",
    "\n",
    "Training the model using `x_train` and `y_train` \n",
    "\n",
    "model=lr.fit(x_train,y_train)\n",
    "\n",
    "Predicting `y_test` using the model.\n",
    "\n",
    "ypred=model.predict(x_test)\n",
    "\n",
    "ypred\n",
    "\n",
    "- Here, `ypred` is the predicted column\n",
    "- Which is equivalent to `y_test`\n",
    "\n",
    "y_test\n",
    "\n",
    "- **R² Score**: Measures how well the model explains the variance in the target variable.\n",
    "- **Mean Absolute Error (MAE)**: Represents the average absolute difference between predicted and actual values.\n",
    "\n",
    "from sklearn.metrics import r2_score,mean_absolute_error\n",
    "r2=r2_score(y_test,ypred)\n",
    "mae=mean_absolute_error(y_test,ypred)\n",
    "print('r2 score:', r2)\n",
    "print('Mean absolute error:', mae)\n",
    "print(\"Intercept:\", lr.intercept_)\n",
    "\n",
    "- The R² score indicates that the model explains approximately 95% of the variance in the target variable, showing a strong fit.\n",
    "- The low Mean Absolute Error (MAE) suggests that the model’s predictions are close to the actual addiction scores.\n",
    "- Overall, the model demonstrates strong predictive performance on unseen test data.\n",
    "- The intercept represents the baseline addiction score predicted by the model when all input features are zero.\n",
    "\n",
    "## KNN Regression\n",
    "\n",
    "- In addition to Linear Regression, KNN Regression is applied to validate and cross-check the model’s predictions.\n",
    "- KNN helps capture potential non-linear relationships that Linear Regression may not fully represent.\n",
    "- Using both models improves confidence in the robustness and reliability of the results.\n",
    "\n",
    "Importing `K-Nearest Neighbors (KNN) Regression` Model\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "metric_k = []\n",
    "\n",
    "neighbors = np.arange(1, 15)\n",
    "\n",
    "for k in neighbors:\n",
    "    knn = KNeighborsRegressor(n_neighbors=k)\n",
    "    model = knn.fit(x_train, y_train)\n",
    "    ypred_knn = model.predict(x_test)\n",
    "    r = r2_score(y_test, ypred_knn)\n",
    "    metric_k.append(r)\n",
    "\n",
    "### KNN Model Evaluation\n",
    "\n",
    "To evaluate the performance of the K-Nearest Neighbors (KNN) Regression model, we test multiple values of **K** (number of neighbors).\n",
    "\n",
    "- **`neighbors`** is created using `np.arange(1, 15)` to generate a range of possible K values. Testing different values of K helps identify the optimal neighborhood size for prediction.\n",
    "- For each value of K, a KNN regressor is trained using the training dataset.\n",
    "- The trained model predicts addiction scores for the test dataset.\n",
    "- The **R² score** is calculated to measure how well the model explains the variance in the target variable.\n",
    "- **`metric_k`** is used to store the R² score corresponding to each value of K.\n",
    "\n",
    "By comparing the values stored in `metric_k`, we can determine the value of K that provides the best predictive performance while avoiding underfitting and overfitting.\n",
    "\n",
    "Training the model using `x_train` and `y_train`\n",
    "\n",
    "metric_k\n",
    "\n",
    "We are plotting a line chart with the number of neighbors (K) on the x-axis and the corresponding R² scores (`metric_k`) on the y-axis to observe how the model’s performance varies with different values of K.\n",
    "\n",
    "plt.plot(neighbors,metric_k,'o-')\n",
    "plt.xlabel(\"Number of Neighbors (K)\")\n",
    "plt.ylabel(\"R² Score\")\n",
    "plt.title(\"R² Score vs Number of Neighbors (K)\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "Although the highest R² score is observed below K = 2, K = 3 is selected as it provides comparable performance with improved stability.\n",
    "\n",
    "- Training the model using K = 3.\n",
    "\n",
    "knn=KNeighborsRegressor(n_neighbors=3)\n",
    "model=knn.fit(x_train,y_train)\n",
    "ypred_knn=model.predict(x_test)\n",
    "\n",
    "Importing `r2_score` and `mean_squared_error` to evaluate the performance of the regression model.\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print('r2 score:',r2_score(y_test,ypred_knn))\n",
    "print('mean squared error:',mean_squared_error(y_test,ypred_knn))\n",
    "\n",
    "- The R² score of approximately 0.94 indicates that the model explains about 93% of the variance in the target variable, demonstrating strong predictive performance.\n",
    "- The low Mean Squared Error (0.12) suggests that the predicted values are very close to the actual values, indicating minimal prediction error.\n",
    "- Together, these metrics show that the model generalizes well to unseen data and is effective for predicting the target variable.\n",
    "\n",
    "### Final Insights\n",
    "\n",
    "- The student social media addiction dataset was thoroughly analyzed using Exploratory Data Analysis (EDA), including missing value detection, outlier evaluation, and multiple visualizations to understand usage patterns and behavioral trends.\n",
    "- Careful feature selection and preprocessing such as encoding categorical variables and applying Min-Max scaling helped improve model stability and performance.\n",
    "- **Linear Regression** achieved a high R² score of approximately **0.95** with a low Mean Absolute Error, indicating a strong linear relationship between the selected features and the addiction score.\n",
    "- The **intercept** from the Linear Regression model represents the baseline addiction score when all input features are zero, providing useful interpretability.\n",
    "- **KNN Regression** achieved an R² score of approximately **0.94** with low prediction error, confirming that the model captures local and non-linear patterns in the data.\n",
    "- The close performance of both models demonstrates strong generalization on unseen data and increases confidence in the robustness of the predictions.\n",
    "- Overall, this project highlights effective data preprocessing, model comparison, and reliable prediction of student social media addiction levels.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
